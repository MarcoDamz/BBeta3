# ChatAgentB - Chatbot IA Multi-Agents ğŸ¤–

Application de Chatbot IA multi-agents permettant de discuter avec des agents configurables et de simuler des conv2. Renseigner :
   - **Nom** : Ex. "Assistant Python"
   - **ModÃ¨le LLM** : Choisir azure.gpt-4.1, azure.gpt-4o, azure.gpt-5.1-turbo
   - **System Prompt** : Instructions pour l'agenttions automatiques entre deux agents.

## ğŸš€ Stack Technique

### Backend
- **Django 5+** - Framework web Python
- **Django REST Framework (DRF)** - API RESTful
- **Uvicorn** - Serveur ASGI haute performance
- **Celery** - Gestion des tÃ¢ches asynchrones
- **Redis** - Broker pour Celery
- **LangChain** - Orchestration des LLM
- **PostgreSQL** - Base de donnÃ©es relationnelle

### Frontend
- **React 18** - Framework JavaScript
- **Tailwind CSS** - Design moderne type ChatGPT
- **Zustand** - Gestion d'Ã©tat
- **Vite** - Build tool rapide
- **Axios** - Client HTTP

### Infrastructure
- **Docker** - Conteneurisation
- **Docker Compose** - Orchestration multi-conteneurs
- **Nginx** - Serveur web pour le frontend

## ğŸ“‹ FonctionnalitÃ©s

### 1. Gestion des Agents
- âœ… CRUD complet des agents IA
- âœ… Configuration LLM (azure.gpt-4.1, azure.gpt-4o, azure.gpt-5.1-turbo)
- âœ… System prompts personnalisables
- âœ… ParamÃ¨tres ajustables (tempÃ©rature, max_tokens)
- âœ… SystÃ¨me de tags/catÃ©gories
- âœ… Duplication d'agents
- âœ… Restriction d'accÃ¨s (admin uniquement)

### 2. Conversations
- âœ… Interface de chat en temps rÃ©el
- âœ… Historique des conversations
- âœ… GÃ©nÃ©ration automatique de titres (via IA)
- âœ… SÃ©lection d'agent dynamique
- âœ… Gestion multi-utilisateurs

### 3. Mode Auto-Chat
- âœ… Conversation automatique entre 2 agents
- âœ… Configuration du nombre d'itÃ©rations
- âœ… Traitement asynchrone (Celery)
- âœ… Enregistrement avec prÃ©fixe "AUTO:"
- âœ… AccÃ¨s admin uniquement

## ğŸ—ï¸ Architecture

```
BBeta3/
â”œâ”€â”€ backend/                    # Backend Django
â”‚   â”œâ”€â”€ chatagentb/            # Configuration projet
â”‚   â”‚   â”œâ”€â”€ settings.py        # Configuration Django
â”‚   â”‚   â”œâ”€â”€ celery.py          # Configuration Celery
â”‚   â”‚   â”œâ”€â”€ urls.py            # Routes principales
â”‚   â”‚   â””â”€â”€ asgi.py            # Configuration ASGI
â”‚   â”œâ”€â”€ agents/                # App gestion agents
â”‚   â”‚   â”œâ”€â”€ models.py          # ModÃ¨le Agent
â”‚   â”‚   â”œâ”€â”€ serializers.py     # Serializers DRF
â”‚   â”‚   â”œâ”€â”€ views.py           # ViewSets API
â”‚   â”‚   â””â”€â”€ urls.py            # Routes agents
â”‚   â”œâ”€â”€ chat/                  # App conversations
â”‚   â”‚   â”œâ”€â”€ models.py          # ModÃ¨les Conversation, Message
â”‚   â”‚   â”œâ”€â”€ serializers.py     # Serializers DRF
â”‚   â”‚   â”œâ”€â”€ views.py           # ViewSets API
â”‚   â”‚   â”œâ”€â”€ tasks.py           # TÃ¢ches Celery
â”‚   â”‚   â”œâ”€â”€ llm_service.py     # Service LangChain
â”‚   â”‚   â””â”€â”€ urls.py            # Routes chat
â”‚   â”œâ”€â”€ requirements.txt       # DÃ©pendances Python
â”‚   â”œâ”€â”€ Dockerfile             # Image Docker backend
â”‚   â””â”€â”€ docker-entrypoint.sh   # Script de dÃ©marrage
â”œâ”€â”€ frontend/                   # Frontend React
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/        # Composants React
â”‚   â”‚   â”‚   â”œâ”€â”€ Sidebar.jsx    # Barre latÃ©rale
â”‚   â”‚   â”‚   â”œâ”€â”€ Header.jsx     # En-tÃªte avec sÃ©lecteur
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatWindow.jsx # Zone de chat
â”‚   â”‚   â”‚   â””â”€â”€ ChatInput.jsx  # Input utilisateur
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatPage.jsx   # Page principale
â”‚   â”‚   â”‚   â””â”€â”€ AdminPage.jsx  # Page admin
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.js         # Client API
â”‚   â”‚   â”œâ”€â”€ store/
â”‚   â”‚   â”‚   â””â”€â”€ useStore.js    # Store Zustand
â”‚   â”‚   â”œâ”€â”€ App.jsx            # Composant racine
â”‚   â”‚   â””â”€â”€ main.jsx           # Point d'entrÃ©e
â”‚   â”œâ”€â”€ package.json           # DÃ©pendances npm
â”‚   â”œâ”€â”€ Dockerfile             # Image Docker frontend
â”‚   â””â”€â”€ nginx.conf             # Configuration Nginx
â”œâ”€â”€ docker-compose.yml          # Orchestration Docker
â”œâ”€â”€ .env.example               # Template variables d'environnement
â””â”€â”€ README.md                  # Documentation
```

## ğŸš¦ Installation et DÃ©marrage

### PrÃ©requis
- Docker Desktop (Windows/Mac) ou Docker Engine + Docker Compose (Linux)
- ClÃ© API OpenAI

### 1. Cloner et Configurer

```powershell
# Cloner le dÃ©pÃ´t (si depuis Git)
git clone <repository-url>
cd BBeta3

# Copier le fichier d'environnement
cp .env.example .env
```

### 2. Configurer les Variables d'Environnement

Ã‰diter le fichier `.env` et **OBLIGATOIREMENT** renseigner votre clÃ© API :

```env
# OBLIGATOIRE - Remplacer par votre vraie clÃ©
OPENAI_API_KEY=sk-your-real-openai-key-here

# OPTIONNEL - URL de base personnalisÃ©e pour l'API OpenAI
# Laissez vide pour utiliser l'API officielle OpenAI
# Utile pour : proxies, Azure OpenAI, endpoints personnalisÃ©s
OPENAI_API_BASE=
```

# Optionnel - Modifier si besoin
POSTGRES_PASSWORD=your-secure-password
DJANGO_SUPERUSER_USERNAME=admin
DJANGO_SUPERUSER_PASSWORD=your-secure-password
```

### 3. Lancer l'Application

```powershell
# Construire et dÃ©marrer tous les services
docker-compose up --build

# Ou en mode dÃ©tachÃ© (arriÃ¨re-plan)
docker-compose up -d --build
```

### 4. AccÃ©der Ã  l'Application

- **Frontend (Interface utilisateur)** : http://localhost:3000
- **Backend API (Documentation)** : http://localhost:8000/api/
- **Admin Django** : http://localhost:8000/admin/

### 5. Identifiants par DÃ©faut

- **Username** : `admin`
- **Password** : `admin123` (ou celui dÃ©fini dans `.env`)

## ğŸ¯ Utilisation

### Configuration des Agents

1. AccÃ©der Ã  la page Admin via le bouton "Admin Config"
2. Cliquer sur "Nouvel Agent"
3. Renseigner :
   - **Nom** : Ex. "Assistant Python"
   - **ModÃ¨le LLM** : Choisir azure.gpt-4.1, Claude 3, etc.
   - **System Prompt** : Instructions pour l'agent
   - **TempÃ©rature** : 0.0 (dÃ©terministe) Ã  1.0 (crÃ©atif)
   - **Max Tokens** : Limite de la rÃ©ponse
4. Sauvegarder

### Chat avec un Agent

1. Retourner sur la page principale
2. SÃ©lectionner un agent dans le header
3. Taper votre message et appuyer sur "Envoyer"
4. L'historique est sauvegardÃ© automatiquement
5. Le titre de la conversation est gÃ©nÃ©rÃ© par IA

### Mode Auto-Chat (Admin uniquement)

1. Page Admin â†’ Bouton "Mode Auto-Chat"
2. SÃ©lectionner Agent A et Agent B
3. Saisir le message initial
4. DÃ©finir le nombre d'itÃ©rations (1-50)
5. Lancer â†’ La tÃ¢che s'exÃ©cute en arriÃ¨re-plan
6. Consulter le rÃ©sultat dans l'historique (titre "AUTO: Agent A â†” Agent B")

## ğŸ› ï¸ Commandes Utiles

### Docker

```powershell
# Voir les logs
docker-compose logs -f

# Logs d'un service spÃ©cifique
docker-compose logs -f backend
docker-compose logs -f worker

# ArrÃªter les services
docker-compose down

# ArrÃªter et supprimer les volumes (rÃ©initialisation complÃ¨te)
docker-compose down -v

# Reconstruire un service spÃ©cifique
docker-compose up -d --build backend
```

### Django (dans le conteneur backend)

```powershell
# AccÃ©der au shell Django
docker-compose exec backend python manage.py shell

# CrÃ©er des migrations
docker-compose exec backend python manage.py makemigrations

# Appliquer les migrations
docker-compose exec backend python manage.py migrate

# CrÃ©er un superutilisateur manuellement
docker-compose exec backend python manage.py createsuperuser

# Collecter les fichiers statiques
docker-compose exec backend python manage.py collectstatic --noinput
```

### Celery

```powershell
# Voir les workers actifs
docker-compose exec worker celery -A chatagentb inspect active

# Voir les tÃ¢ches en attente
docker-compose exec worker celery -A chatagentb inspect scheduled

# Purger toutes les tÃ¢ches
docker-compose exec worker celery -A chatagentb purge
```

## âš™ï¸ Configuration AvancÃ©e

### URL de Base PersonnalisÃ©e (OPENAI_API_BASE)

La variable `OPENAI_API_BASE` permet de spÃ©cifier un endpoint personnalisÃ© pour l'API OpenAI. Elle est optionnelle.

#### Cas d'usage :

1. **Azure OpenAI Service** :
   ```env
   OPENAI_API_BASE=https://your-resource.openai.azure.com/openai/deployments/your-deployment
   ```

2. **Proxy d'entreprise** :
   ```env
   OPENAI_API_BASE=https://proxy.votre-entreprise.com/openai/v1
   ```

3. **Endpoint personnalisÃ©** (compatible OpenAI) :
   ```env
   OPENAI_API_BASE=https://api.votre-llm.com/v1
   ```

4. **API OpenAI officielle** (par dÃ©faut) :
   ```env
   OPENAI_API_BASE=
   # ou
   OPENAI_API_BASE=https://api.openai.com/v1
   ```

**Note** : Laissez vide pour utiliser automatiquement l'API officielle OpenAI.

## ğŸ” SÃ©curitÃ©

### En Production

1. **Variables d'environnement** :
   ```env
   DEBUG=False
   SECRET_KEY=<gÃ©nÃ©rer une clÃ© sÃ©curisÃ©e : python -c "from django.core.management.utils import get_random_secret_key; print(get_random_secret_key())">
   ALLOWED_HOSTS=votre-domaine.com
   ```

2. **Base de donnÃ©es** :
   - Utiliser un mot de passe fort
   - Activer SSL/TLS
   - Sauvegardes rÃ©guliÃ¨res

3. **CORS** :
   ```env
   CORS_ALLOWED_ORIGINS=https://votre-domaine.com
   ```

4. **HTTPS** :
   - Configurer un reverse proxy (Nginx/Traefik)
   - Certificat SSL (Let's Encrypt)

## ğŸŒ DÃ©ploiement GCP

### Cloud Run + Cloud SQL

1. **Cloud SQL** :
   ```bash
   gcloud sql instances create chatagentb-db \
     --database-version=POSTGRES_15 \
     --tier=db-f1-micro \
     --region=europe-west1
   ```

2. **Container Registry** :
   ```bash
   docker tag chatagentb-backend gcr.io/PROJECT_ID/chatagentb-backend
   docker push gcr.io/PROJECT_ID/chatagentb-backend
   ```

3. **Cloud Run** :
   ```bash
   gcloud run deploy chatagentb-backend \
     --image gcr.io/PROJECT_ID/chatagentb-backend \
     --add-cloudsql-instances PROJECT_ID:europe-west1:chatagentb-db \
     --set-env-vars POSTGRES_HOST=/cloudsql/PROJECT_ID:europe-west1:chatagentb-db
   ```

## ğŸ“Š API Endpoints

### Agents

- `GET /api/agents/` - Liste des agents
- `GET /api/agents/{id}/` - DÃ©tails d'un agent
- `POST /api/agents/` - CrÃ©er un agent (admin)
- `PUT /api/agents/{id}/` - Modifier un agent (admin)
- `DELETE /api/agents/{id}/` - Supprimer un agent (admin)
- `POST /api/agents/{id}/duplicate/` - Dupliquer un agent (admin)

### Conversations

- `GET /api/chat/conversations/` - Liste des conversations
- `GET /api/chat/conversations/{id}/` - DÃ©tails d'une conversation
- `POST /api/chat/conversations/` - CrÃ©er une conversation
- `DELETE /api/chat/conversations/{id}/` - Supprimer une conversation
- `POST /api/chat/conversations/send_message/` - Envoyer un message
- `POST /api/chat/conversations/auto_chat/` - Lancer un auto-chat (admin)

### Messages

- `GET /api/chat/messages/` - Liste des messages
- `GET /api/chat/messages/{id}/` - DÃ©tails d'un message

## ğŸ§ª Tests

```powershell
# Tests Django
docker-compose exec backend python manage.py test

# Tests avec couverture
docker-compose exec backend coverage run --source='.' manage.py test
docker-compose exec backend coverage report
```

## ğŸ› DÃ©pannage

### ProblÃ¨me : Le backend ne dÃ©marre pas

```powershell
# VÃ©rifier les logs
docker-compose logs backend

# RecrÃ©er la base de donnÃ©es
docker-compose down -v
docker-compose up -d db
docker-compose up backend
```

### ProblÃ¨me : Celery ne traite pas les tÃ¢ches

```powershell
# VÃ©rifier que Redis fonctionne
docker-compose exec redis redis-cli ping
# RÃ©ponse attendue: PONG

# RedÃ©marrer le worker
docker-compose restart worker
```

### ProblÃ¨me : Erreur "LLM API Key not found"

- VÃ©rifier que les clÃ©s API sont bien dans `.env`
- RedÃ©marrer les services : `docker-compose restart`

## ğŸ“ TODO / AmÃ©liorations Futures

- [ ] Authentification JWT pour le frontend
- [ ] Support des fichiers (upload de documents)
- [ ] Export des conversations (PDF, Markdown)
- [ ] Streaming des rÃ©ponses LLM (SSE)
- [ ] Analytics et tableaux de bord
- [ ] Tests unitaires et d'intÃ©gration
- [ ] CI/CD (GitHub Actions)
- [ ] Multi-langue (i18n)

## ğŸ“„ Licence

Ce projet est sous licence MIT.

## ğŸ‘¨â€ğŸ’» Auteur

DÃ©veloppÃ© pour dÃ©monstration d'architecture moderne avec Django, React, Celery, LangChain et Docker.

---

**Note** : Ce projet nÃ©cessite une clÃ© API OpenAI pour fonctionner. Les modÃ¨les LLM gÃ©nÃ¨rent des coÃ»ts selon votre utilisation.
